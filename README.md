# ğŸ“¡ kafka-spark-realtime â€” Real-Time Clickstream Analytics Pipeline

> A complete end-to-end pipeline for real-time analytics using Kafka + Spark Structured Streaming + PostgreSQL + Elasticsearch.

---

## ğŸ“Œ Overview

It simulates and processes clickstream data in real time. It uses:

- **Kafka** to ingest user click events
- **Spark Structured Streaming** (via PySpark) for stream processing
- **PostgreSQL** to store historical data
- **Elasticsearch + Kibana** for search & visualization

Optional tools like Kafka Connect and Kafdrop are also included.

---

## ğŸ§± Architecture

```

\[Simulator (Go/Python)]
â†“
\[Kafka Topic: clicks]
â†“
\[Spark Structured Streaming]
â†“           â†˜
\[PostgreSQL]   \[Elasticsearch]
â†“
\[Kibana]

```

---

## ğŸš€ Features

- âœ… Real-time event simulation (Go or Python)
- âœ… Kafka producer/consumer pipeline
- âœ… Stream processing with PySpark
- âœ… Sink to PostgreSQL and Elasticsearch
- âœ… Docker Compose setup for full reproducibility
- âœ… Extensible and production-oriented

---

## ğŸ› ï¸ Tech Stack

| Tool              | Role                                |
|-------------------|-------------------------------------|
| **Kafka**         | Message broker for real-time events |
| **Spark**         | Stream processing engine (PySpark)  |
| **PostgreSQL**    | Storage of historical events        |
| **Elasticsearch** | Real-time search and analytics      |
| **Kibana**        | Visualization UI (optional)         |
| **Kafka Connect** | Sink connectors (optional)          |
| **Docker Compose**| Environment orchestration           |

---

## ğŸ“‚ Project Structure

```

ksr/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ simulator/
â”‚   â””â”€â”€ main.go or send\_clicks.py
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ stream\_processor.py
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ create\_tables.sql
â”œâ”€â”€ connectors/
â”‚   â”œâ”€â”€ postgres-sink.json
â”‚   â””â”€â”€ elastic-sink.json
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratory\_analysis.ipynb
â””â”€â”€ README.md

````

---

## â–¶ï¸ Quick Start

1. **Clone the repo**
```bash
git clone https://github.com//ksr.git
cd eventpulse
````

2. **Launch the environment**

```bash
docker-compose up -d
```

3. **Start the simulator**

```bash
go run simulator/main.go
# or
python simulator/send_clicks.py
```

4. **Launch the Spark job**

```bash
spark-submit spark/stream_processor.py
```

5. **Explore**

* PostgreSQL: `localhost:5432`
* Elasticsearch: `localhost:9200`
* Kibana: `localhost:5601`
* Kafdrop: `localhost:9000`

---

## ğŸ“Š Example Event Format

```json
{
  "user_id": "user_42",
  "page": "/product/1234",
  "event": "click",
  "timestamp": "2025-06-04T12:00:00Z"
}
```

---

## ğŸ¤ License

MIT License â€” feel free to use for academic or enterprise learning.

---
